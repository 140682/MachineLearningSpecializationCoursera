{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_outer_tags(filename):\n",
    "    with open(filename, 'r+') as f:        \n",
    "        content = f.read()        \n",
    "        f.seek(0, 0)\n",
    "        firstline = f.readline()\n",
    "        if '<data>' not in firstline:            \n",
    "            f.seek(0, 0)\n",
    "            f.write('<data>' + '\\n' + content + '\\n</data>')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_target(row):\n",
    "   if row['rating'] < 4:\n",
    "      return 0\n",
    "   else:\n",
    "      return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data_set(data):\n",
    "    data['target'] = data.apply(lambda row: make_target(row),axis=1)\n",
    "    data = data.dropna(subset=['target'])\n",
    "    data['target'] = data['target'].astype(int)   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_tree(etree):\n",
    "    n = -1\n",
    "    for review in etree.iter('review'):\n",
    "        n += 1\n",
    "        yield (n, review.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataframes(training_data_file, test_data_file):\n",
    "    df_training = pd.read_json(training_data_file)\n",
    "    df_training = prepare_data_set(df_training)\n",
    "    \n",
    "    add_outer_tags(test_data_file)\n",
    "    tree = etree.parse(test_data_file)\n",
    "    df_test = pd.DataFrame(list(iter_tree(tree)), columns=['id', 'text'])\n",
    "    \n",
    "    return df_training, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(df_training, df_test):\n",
    "    X_train = df_training['text'].values\n",
    "    X_test = df_test['text'].values\n",
    "    id_test = df_test['id'].values\n",
    "    y_train = df_training['target'].values              \n",
    "    print len(X_train)\n",
    "    return X_train, y_train, id_test, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pipeline_and_params_1():    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SGDClassifier()),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.75, 1),\n",
    "        #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "        'vect__ngram_range': ((1, 1), (1, 3), (1, 2)),  # unigrams or bigrams\n",
    "        #'tfidf__use_idf': (True, False),\n",
    "        #'tfidf__norm': ('l1', 'l2'),\n",
    "        #'clf__alpha': (0.00001, 0.000001),\n",
    "        #'clf__penalty': ('l2', 'elasticnet'),\n",
    "        #'clf__n_iter': (10, 50, 80),\n",
    "    }\n",
    "    return pipeline, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pipeline_and_params_2():\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('logreg', LogisticRegression()),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'tfidf__max_df': (0.6,0.8,1),\n",
    "        #'tfidf__min_df': (0, 5, 10, 15),\n",
    "        'tfidf__ngram_range': ((1, 1), (1, 2), (1,3), (2,3)),  # unigrams or bigrams\n",
    "        #'tfidf__use_idf': (True, False),\n",
    "        #'tfidf__norm': ('l1', 'l2'),   \n",
    "        #'logreg__C': (0.0001, 0.01, 1),\n",
    "        #'logreg__penalty': ('l2', 'l1'),  \n",
    "    }\n",
    "    return pipeline, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pipeline_and_params_3():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('logreg', LogisticRegression()),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.6, 1.0),\n",
    "        'vect__min_df': (0, 5),\n",
    "        #'vect__stop_words': ('english', None),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams        \n",
    "        #'logreg__C': (0.0001, 0.01, 1),\n",
    "        #'logreg__penalty': ('l2', 'l1'),        \n",
    "    }\n",
    "    return pipeline, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(predictor, data_train, y, id_test, data_test, cv_score=None):\n",
    "    predictor.fit(data_train, y)\n",
    "    joblib.dump(predictor, './SentimentAnalysisModel.pkl')    \n",
    "    prediction = predictor.predict(data_test)\n",
    "    #print predictor\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    filepath_prediction = 'data/prediction-%s-data.csv' % timestamp\n",
    "    filepath_description = 'data/prediction-%s-estimator.txt' % timestamp\n",
    "    \n",
    "    #############\n",
    "    df_true = pd.read_csv('etalon.csv')\n",
    "    y_true = df_true['y'].values\n",
    "    print 'ACCURACY: %.6f' % accuracy_score(y_true, prediction)\n",
    "    #############\n",
    "\n",
    "    prediction_str = ['pos' if p == 1 else 'neg' for p in prediction]\n",
    "    # Create a dataframe with predictions and write it to CSV file   \n",
    "    predictions_df = pd.DataFrame(data=prediction_str, columns=['y'])\n",
    "    predictions_df.to_csv(filepath_prediction, sep=',', index_label='Id')\n",
    "\n",
    "    # Write a short description of the classifier that was used\n",
    "    f = open(filepath_description, 'w')\n",
    "    f.write(str(predictor))\n",
    "    score = '\\nCross-validation score %.8f' % cv_score    \n",
    "    f.write(score)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_grid_search(pipeline, parameters, X_train, y_train):\n",
    "    grid_search = GridSearchCV(pipeline, parameters, scoring='accuracy')\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print \"done in %0.3fs\" % (time() - t0)\n",
    "    \n",
    "    print(\"Best score: %.4f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_experiment(X_train, y_train, id_test, X_test, get_pipeline_and_params):      \n",
    "    pipeline, parameters = get_pipeline_and_params()\n",
    "    gs = do_grid_search(pipeline, parameters, X_train, y_train)\n",
    "    predict(gs.best_estimator_, X_train, y_train, id_test, X_test, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_training, df_test = get_dataframes('reviews11665.json', 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>В сегменте бюджетников, за такую цену, недоста...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Недостатков кроме маленькой памяти нет, разве ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Нет гарнитуры в комплекте. Пожадничали корейцы...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Постоянно глючит. Нормально смогла попользоват...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Сказать что батарея слабая-не сказать ничего. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                               text  target\n",
       "0       1  В сегменте бюджетников, за такую цену, недоста...       0\n",
       "1       1  Недостатков кроме маленькой памяти нет, разве ...       0\n",
       "2       1  Нет гарнитуры в комплекте. Пожадничали корейцы...       0\n",
       "3       1  Постоянно глючит. Нормально смогла попользоват...       0\n",
       "4       1  Сказать что батарея слабая-не сказать ничего. ...       0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ужасно слабый аккумулятор, это основной минус ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ценанадежность-неубиваемостьдолго держит батар...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>подробнее в комментариях\\nК сожалению, факт по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>я любительница громкой музыки. Тише телефона у...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Дата выпуска - 2011 г, емкость - 1430 mAh, тех...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0  Ужасно слабый аккумулятор, это основной минус ...\n",
       "1   1  ценанадежность-неубиваемостьдолго держит батар...\n",
       "2   2  подробнее в комментариях\\nК сожалению, факт по...\n",
       "3   3  я любительница громкой музыки. Тише телефона у...\n",
       "4   4  Дата выпуска - 2011 г, емкость - 1430 mAh, тех..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11665\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, id_test, X_test = read_data(df_training, df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 41.060s\n",
      "Best score: 0.9459\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__ngram_range: (1, 2)\n",
      "ACCURACY: 0.970000\n"
     ]
    }
   ],
   "source": [
    "do_experiment(X_train, y_train, id_test, X_test, get_pipeline_and_params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 92.748s\n",
      "Best score: 0.9314\n",
      "Best parameters set:\n",
      "\ttfidf__max_df: 0.6\n",
      "\ttfidf__ngram_range: (1, 2)\n",
      "ACCURACY: 0.930000\n"
     ]
    }
   ],
   "source": [
    "do_experiment(X_train, y_train, id_test, X_test, get_pipeline_and_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 38.136s\n",
      "Best score: 0.9324\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.6\n",
      "\tvect__min_df: 0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "ACCURACY: 0.950000\n"
     ]
    }
   ],
   "source": [
    "do_experiment(X_train, y_train, id_test, X_test, get_pipeline_and_params_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
